web-crawler
===========

Simple tool to crawl a single domain (to a specified depth) and store content for offline use.


Goals (all are a work-in-progress):

1. parse and cache content from a single domain for offline use (e.g., to store some reference material so I can code on a plane.)

2. enable automatic diffs of pages across time.

4. (possibly) gen a graph-like visualization of the site's structure and use it to show drift over time. Something like this could be useful to correlate with user flows.

3. learn clojure via a real project, specifically learn more about clojure's tree processing (meta-level goal).
